{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(*args):\n",
    "    max_results_city = 120\n",
    "    step = 10\n",
    "    job_search = \"data+analyst\"\n",
    "    if args:\n",
    "        cities = set(args)\n",
    "    else:\n",
    "        cities = {\"New York\", \"San Francisco\"}\n",
    "\n",
    "    city_search = [city.replace(\" \", \"+\") for city in cities]\n",
    "    city_search.sort()\n",
    "    \n",
    "    city_list = [city for city in cities] * max_results_city\n",
    "    city_list.sort()\n",
    "   \n",
    "    url_list = get_url_list(city_search, job_search, max_results_city, step)\n",
    "\n",
    "    results = scrape_links(url_list)\n",
    "    results[\"search_city\"] = city_list\n",
    "    \n",
    "    jobs_df = get_dataframe(results)\n",
    "    # Save to new csv file\n",
    "    output = os.path.join('..', '03_Data', 'Job_Data.csv')\n",
    "    jobs_df.to_csv(output, header=True, index=True, index_label=\"Id\", encoding=\"utf-8-sig\")\n",
    "    print(\"Done\")\n",
    "    data = jobs_df.to_dict(orient=\"records\")\n",
    "    insert_to_tables(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_list(city_search, job_search, max_results_city, step):\n",
    "    url_list = []\n",
    "    for city in city_search:\n",
    "        for start in range(0, max_results_city, step):\n",
    "            search_url = \"http://www.indeed.com/jobs?q=\"+str(job_search)+\"&l=\"+str(city)+\"&start=\"+str(start)\n",
    "            results_page = requests.get(search_url)\n",
    "            #browser.visit(search_url)\n",
    "            time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "            #html = browser.html\n",
    "            soup = BeautifulSoup(results_page.text, \"lxml\",)\n",
    "\n",
    "            h2 = soup.find_all('h2', class_=\"jobtitle\")\n",
    "            for stuff in h2:\n",
    "                href = stuff.find('a')['href']\n",
    "                url = \"http://www.indeed.com/\"+str(href)\n",
    "                url_list.append(url)\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(url_list):\n",
    "    job_company = []\n",
    "    job_desc = []\n",
    "    job_location = []\n",
    "    job_title = []\n",
    "\n",
    "    for url in url_list:\n",
    "        job_page = requests.get(url,)\n",
    "        time.sleep(1) \n",
    "        \n",
    "        job_soup = BeautifulSoup(job_page.text, \"lxml\")\n",
    "        \n",
    "        title=company=location=job_summary=\"No information\"\n",
    "            \n",
    "        title_object = job_soup.find(\"b\", class_=\"jobtitle\")\n",
    "        if title_object is not None:\n",
    "            title = title_object.text\n",
    "        job_title.append(title)\n",
    "\n",
    "        company_object = job_soup.find(\"span\", class_=\"company\")\n",
    "        if company_object is not None:\n",
    "            company = company_object.text\n",
    "        job_company.append(company)\n",
    "\n",
    "        location_object = job_soup.find(\"span\", class_=\"location\")\n",
    "        if location_object is not None:\n",
    "            location = location_object.text\n",
    "        job_location.append(location)\n",
    "\n",
    "        job_summary_object = job_soup.find(\"span\", id=\"job_summary\")\n",
    "        if job_summary_object is not None:\n",
    "            job_summary = job_summary_object.get_text()\n",
    "            \n",
    "        job_desc.append(job_summary)\n",
    "        \n",
    "    \n",
    "    result = { \"title\":job_title,\n",
    "               \"description\": job_desc, \n",
    "               \"location\": job_location,\n",
    "               \"company\": job_company,\n",
    "               \"link\" : url_list\n",
    "             }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(results):\n",
    "    jobs_df = pd.DataFrame.from_dict(results)\n",
    "    jobs_df = jobs_df.dropna(how='any')\n",
    "    jobs_df = jobs_df[[\"title\",\"company\", \"location\",\"description\", \"search_city\", \"link\"]]\n",
    "    jobs_df.index = np.arange(1, len(jobs_df) + 1)\n",
    "    return jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and boilerplate\n",
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, Numeric, Text, Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a JobPosition class\n",
    "### BEGIN SOLUTION\n",
    "class DataAnalyticsJob(Base):\n",
    "    __tablename__ = \"job_position\"\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    title = Column(String)\n",
    "    company = Column(String) \n",
    "    location = Column(String) \n",
    "    description = Column(Text) \n",
    "    search_city = Column(String) \n",
    "    link = Column(String) \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"id={self.id}, title={self.title}\"\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_to_tables(data_result):\n",
    "    # Create an engine to a SQLite database file\n",
    "    #Unix/Mac - 4 initial slashes in total\n",
    "    #engine = create_engine('sqlite:////absolute/path/to/foo.db')\n",
    "    engine = create_engine(\"sqlite:///db/datanalyticsjobs.sqlite\")\n",
    "    # Create a connection to the engine called `conn`\n",
    "    conn = engine.connect()\n",
    "    # Use `create_all` to create the customers table in the database\n",
    "    Base.metadata.create_all(engine)\n",
    "    # Use MetaData from SQLAlchemy to reflect the tables\n",
    "    ### BEGIN SOLUTION\n",
    "    metadata = MetaData(bind=engine)\n",
    "    metadata.reflect()\n",
    "    ### END SOLUTION\n",
    "    # Save the reference to the `customers` table as a variable called `table`\n",
    "    table = sqlalchemy.Table('job_position', metadata, autoload=True)\n",
    "    # Use `table.delete()` to remove any pre-existing data.\n",
    "    # Note that this is a convenience function so that you can re-run the example code multiple times.\n",
    "    # You would not likely do this step in production.\n",
    "    conn.execute(table.delete())\n",
    "    # Use `table.insert()` to insert the data into the table\n",
    "    # The SQL table is populated during this step\n",
    "    conn.execute(table.insert(), data_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "data_result=scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [PythonData]",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
