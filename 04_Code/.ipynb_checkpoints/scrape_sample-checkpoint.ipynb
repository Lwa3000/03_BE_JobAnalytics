{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def scrape(*args):\n",
    "    city_search=set(args)\n",
    "    return city_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New+York', 'New+York', 'New+York', 'New+York', 'New+York', 'New+York', 'New+York', 'New+York', 'New+York', 'New+York', 'Os', 'Os', 'Os', 'Os', 'Os', 'Os', 'Os', 'Os', 'Os', 'Os', 'San+Francisco', 'San+Francisco', 'San+Francisco', 'San+Francisco', 'San+Francisco', 'San+Francisco', 'San+Francisco', 'San+Francisco', 'San+Francisco', 'San+Francisco']\n"
     ]
    }
   ],
   "source": [
    "lista=scrape(\"New York\", \"San Francisco\", \"Os\")\n",
    "search_city_list= [city.replace(\" \", \"+\") for city in lista] * 10\n",
    "search_city_list.sort()\n",
    "print(search_city_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'New York', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco', 'San Francisco']\n"
     ]
    }
   ],
   "source": [
    "max_results_city = 100\n",
    "step = 10\n",
    "city_search = [\"New+York\", \"San+Francisco\"]\n",
    "job_search = \"data+analyst\"\n",
    "\n",
    "url_list = [] # will hold list of urls for each job\n",
    "search_city_list= [city.replace(\"+\", \" \") for city in city_search] * max_results_city\n",
    "search_city_list.sort()\n",
    "print(search_city_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "for city in city_search:\n",
    "    for start in range(0, max_results_city, step):\n",
    "        search_url = \"http://www.indeed.com/jobs?q=\"+str(job_search)+\"&l=\"+str(city)+\"&start=\"+str(start)\n",
    "        results_page = requests.get(search_url)\n",
    "        #browser.visit(search_url)\n",
    "        time.sleep(2)  #ensuring at least 1 second between page grabs\n",
    "        #html = browser.html\n",
    "        soup = BeautifulSoup(results_page.text, \"lxml\",)\n",
    "\n",
    "        h2 = soup.find_all('h2', class_=\"jobtitle\")\n",
    "        for stuff in h2:\n",
    "            href = stuff.find('a')['href']\n",
    "            url = \"http://www.indeed.com/\"+str(href)\n",
    "            url_list.append(url)\n",
    "            \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company = []\n",
    "job_desc = []\n",
    "job_location = []\n",
    "job_title = []\n",
    "job_salary = []\n",
    "job_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for url in url_list:\n",
    "    job_page = requests.get(url,)\n",
    "    time.sleep(1) \n",
    "    \n",
    "    job_soup = BeautifulSoup(job_page.text, \"lxml\")\n",
    "    \n",
    "    title=company=location=job_summary=\"\"\n",
    "        \n",
    "    title_object = job_soup.find(\"b\", class_=\"jobtitle\")\n",
    "    if title_object is not None:\n",
    "        title = title_object.text\n",
    "    job_title.append(title)\n",
    "\n",
    "    company_object = job_soup.find(\"span\", class_=\"company\")\n",
    "    if company_object is not None:\n",
    "        company = company_object.text\n",
    "    job_company.append(company)\n",
    "\n",
    "    location_object = job_soup.find(\"span\", class_=\"location\")\n",
    "    if location_object is not None:\n",
    "        location = location_object.text\n",
    "    job_location.append(location)\n",
    "\n",
    "    job_summary_object = job_soup.find(\"span\", id=\"job_summary\")\n",
    "    if job_summary_object is not None:\n",
    "        job_summary = job_summary_object.get_text()\n",
    "        \n",
    "    job_desc.append(job_summary)\n",
    "    \n",
    "    job_url.append(url)\n",
    "\n",
    "\n",
    "print(len(job_title))\n",
    "print(len(job_desc))\n",
    "print(len(job_location))\n",
    "print(len(job_company))\n",
    "print(len(job_url))\n",
    "print(len(search_city_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = pd.DataFrame({\"Title\": job_title,\n",
    "                           \"Company\": job_company,\n",
    "                           \"Location\": job_location,\n",
    "                           \"Description\": job_desc,\n",
    "                           #\"Salary\" : job_salary\n",
    "                           \"Link\": job_url,\n",
    "                           \"Search_City\": search_city_list})\n",
    "\n",
    "example_df = example_df[[\"Title\",\"Company\", \"Location\",\"Description\", \"Search_City\", \"Link\"]]\n",
    "example_df.index = np.arange(1, len(example_df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Search_City</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>QBE</td>\n",
       "      <td>New York State</td>\n",
       "      <td>To assist Development Leads for Proof of Conce...</td>\n",
       "      <td>New York</td>\n",
       "      <td>http://www.indeed.com//rc/clk?jk=be1de9ec0bd2e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Acacia Technical Services</td>\n",
       "      <td>New York State</td>\n",
       "      <td>Title: Data Analyst\\nLocation either NYC or Pa...</td>\n",
       "      <td>New York</td>\n",
       "      <td>http://www.indeed.com//rc/clk?jk=f9bc2efbe1dfb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>About the position:\\nWirecutter is seeking a D...</td>\n",
       "      <td>New York</td>\n",
       "      <td>http://www.indeed.com//rc/clk?jk=2f4ab0a8ac3e0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst, Optimization</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>The New York Times is seeking a Data Analyst t...</td>\n",
       "      <td>New York</td>\n",
       "      <td>http://www.indeed.com//rc/clk?jk=9490bd919be4a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>New York, NY 10032</td>\n",
       "      <td>he Data Management Organization (DMO) is leadi...</td>\n",
       "      <td>New York</td>\n",
       "      <td>http://www.indeed.com//rc/clk?jk=1c57c8959e16f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Title                    Company            Location  \\\n",
       "1         Data Analyst Intern                        QBE      New York State   \n",
       "2                Data Analyst  Acacia Technical Services      New York State   \n",
       "3                Data Analyst         The New York Times        New York, NY   \n",
       "4  Data Analyst, Optimization         The New York Times        New York, NY   \n",
       "5                Data Analyst             Morgan Stanley  New York, NY 10032   \n",
       "\n",
       "                                         Description Search_City  \\\n",
       "1  To assist Development Leads for Proof of Conce...    New York   \n",
       "2  Title: Data Analyst\\nLocation either NYC or Pa...    New York   \n",
       "3  About the position:\\nWirecutter is seeking a D...    New York   \n",
       "4  The New York Times is seeking a Data Analyst t...    New York   \n",
       "5  he Data Management Organization (DMO) is leadi...    New York   \n",
       "\n",
       "                                                Link  \n",
       "1  http://www.indeed.com//rc/clk?jk=be1de9ec0bd2e...  \n",
       "2  http://www.indeed.com//rc/clk?jk=f9bc2efbe1dfb...  \n",
       "3  http://www.indeed.com//rc/clk?jk=2f4ab0a8ac3e0...  \n",
       "4  http://www.indeed.com//rc/clk?jk=9490bd919be4a...  \n",
       "5  http://www.indeed.com//rc/clk?jk=1c57c8959e16f...  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../03_Data/Job_Data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save to new csv file\n",
    "output = os.path.join('..', '03_Data', 'Job_Data.csv')\n",
    "print(output)\n",
    "example_df.to_csv(output, header=True, index=True, index_label='Job_Id', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [PythonData]",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
